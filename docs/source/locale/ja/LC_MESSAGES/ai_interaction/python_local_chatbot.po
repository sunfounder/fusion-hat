# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2026, SunFounder
# This file is distributed under the same license as the SunFounder Fusion
# HAT+ package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2026.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SunFounder Fusion HAT+ \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-08 09:43+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: ja\n"
"Language-Team: ja <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.15.0\n"

#: ../ai_interaction/python_local_chatbot.rst:3
msgid ""
"Hello, welcome to the SunFounder Raspberry Pi & Arduino & ESP32 "
"Enthusiasts Community on Facebook! Dive deeper into Raspberry Pi, "
"Arduino, and ESP32 with fellow enthusiasts."
msgstr ""
"ã“ã‚“ã«ã¡ã¯ã€‚SunFounder Raspberry Pi & Arduino & ESP32 "
"Facebook æ„›å¥½å®¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸ã‚ˆã†ã“ãï¼ "
"Raspberry Piã€Arduinoã€ESP32 ã«ã¤ã„ã¦ã€ä»²é–“ã®æ„›å¥½å®¶ã¨ä¸€ç·’ã«ã•ã‚‰ã«æ·±ãæ¢æ±‚ã—ã¾ã—ã‚‡ã†ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:5
msgid "**Why Join?**"
msgstr "**å‚åŠ ã™ã‚‹ç†ç”±** "

#: ../ai_interaction/python_local_chatbot.rst:7
msgid ""
"**Expert Support**: Solve post-sale issues and technical challenges with "
"help from our community and team."
msgstr ""
"**å°‚é–€çš„ãªã‚µãƒãƒ¼ãƒˆ** ï¼šã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¡ãƒ³ãƒãƒ¼ã‚„å…¬å¼ãƒãƒ¼ãƒ ã®æ”¯æ´ã‚’å—ã‘ã¦ã€"
"è³¼å…¥å¾Œã®å•é¡Œã‚„æŠ€è¡“çš„ãªèª²é¡Œã‚’è§£æ±ºã§ãã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:8
msgid "**Learn & Share**: Exchange tips and tutorials to enhance your skills."
msgstr "**å­¦ã³ã¨å…±æœ‰** ï¼šãƒ’ãƒ³ãƒˆã‚„ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’äº¤æ›ã—ã€ã‚¹ã‚­ãƒ«ã‚’å‘ä¸Šã•ã›ã¾ã—ã‚‡ã†ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:9
msgid ""
"**Exclusive Previews**: Get early access to new product announcements and"
" sneak peeks."
msgstr ""
"**é™å®šå…ˆè¡Œæƒ…å ±** ï¼šæ–°è£½å“ã®ç™ºè¡¨ã‚„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±ã‚’ã„ã¡æ—©ãå…¥æ‰‹ã§ãã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:10
msgid "**Special Discounts**: Enjoy exclusive discounts on our newest products."
msgstr "**ç‰¹åˆ¥å‰²å¼•** ï¼šæœ€æ–°è£½å“ã‚’å¯¾è±¡ã¨ã—ãŸé™å®šå‰²å¼•ã‚’ãŠæ¥½ã—ã¿ã„ãŸã ã‘ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:11
msgid ""
"**Festive Promotions and Giveaways**: Take part in giveaways and holiday "
"promotions."
msgstr ""
"**å­£ç¯€é™å®šãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆä¼ç”»** ï¼š"
"ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚„ç¥æ—¥é™å®šã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã«å‚åŠ ã§ãã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:13
msgid ""
"ğŸ‘‰ Ready to explore and create with us? Click [|link_sf_facebook|] and "
"join today!"
msgstr ""
"ğŸ‘‰ ç§ãŸã¡ã¨ä¸€ç·’ã«æ¢æ±‚ã—ã€å‰µé€ ã™ã‚‹æº–å‚™ã¯ã§ãã¾ã—ãŸã‹ï¼Ÿ "
"[|link_sf_facebook|] ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ä»Šã™ãå‚åŠ ã—ã¾ã—ã‚‡ã†ï¼"

#: ../ai_interaction/python_local_chatbot.rst:16
msgid "6. Local Voice Chatbot"
msgstr "6. ãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ"

#: ../ai_interaction/python_local_chatbot.rst:18
msgid ""
"In this lesson, you will combine everything you've learned â€” **speech "
"recognition (STT)**, **text-to-speech (TTS)**, and a **local LLM "
"(Ollama)** â€” to build a fully offline **voice chatbot** that runs on your"
" Fusion HAT."
msgstr ""
"ã“ã®ãƒ¬ãƒƒã‚¹ãƒ³ã§ã¯ã€ã“ã‚Œã¾ã§å­¦ã‚“ã å†…å®¹ â€” **éŸ³å£°èªè­˜ï¼ˆ STT ï¼‰**ã€ **éŸ³å£°åˆæˆï¼ˆ TTS ï¼‰**ã€"
"ãã—ã¦ **ãƒ­ãƒ¼ã‚«ãƒ« LLMï¼ˆ Ollama ï¼‰** â€” ã‚’çµ„ã¿åˆã‚ã›ã¦ã€"
"Fusion HAT ä¸Šã§å‹•ä½œã™ã‚‹ã€å®Œå…¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã® **éŸ³å£°ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ** ã‚’ä½œæˆã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:22
msgid "The workflow is simple:"
msgstr "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã™ï¼š"

#: ../ai_interaction/python_local_chatbot.rst:24
msgid ""
"**Listen** â€” The microphone captures your speech and transcribes it with "
"**Vosk**."
msgstr ""
"**èã** â€” ãƒã‚¤ã‚¯ãŒéŸ³å£°ã‚’åéŸ³ã—ã€ **Vosk** ã§æ–‡å­—èµ·ã“ã—ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:25
msgid ""
"**Think** â€” The text is sent to a local **LLM** running on Ollama (e.g., "
"``llama3.2:3b``)."
msgstr ""
"**è€ƒãˆã‚‹** â€” ãƒ†ã‚­ã‚¹ãƒˆã‚’ Ollama ä¸Šã§å‹•ä½œã™ã‚‹ãƒ­ãƒ¼ã‚«ãƒ« **LLM**ï¼ˆä¾‹ï¼š ``llama3.2:3b`` ï¼‰ã¸é€ä¿¡ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:26
msgid "**Speak** â€” The chatbot answers aloud using **Piper TTS**."
msgstr "**è©±ã™** â€” ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒ **Piper TTS** ã‚’ä½¿ã£ã¦éŸ³å£°ã§è¿”ç­”ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:28
msgid ""
"This creates a **hands-free conversational robot** that can understand "
"and respond in real time."
msgstr ""
"ã“ã‚Œã«ã‚ˆã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç†è§£ã—ã¦å¿œç­”ã§ãã‚‹ **ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ä¼šè©±ãƒ­ãƒœãƒƒãƒˆ** ãŒå®Ÿç¾ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:33
msgid "Before You Start"
msgstr "å§‹ã‚ã‚‹å‰ã«"

#: ../ai_interaction/python_local_chatbot.rst:35
msgid "Make sure you have prepared the following:"
msgstr "ä»¥ä¸‹ãŒæº–å‚™ã§ãã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š"

#: ../ai_interaction/python_local_chatbot.rst:37
msgid "Tested **Piper TTS** (:ref:`test_piper`) and chosen a working voice model."
msgstr "**Piper TTS** ï¼ˆ :ref:`test_piper` ï¼‰ã‚’ãƒ†ã‚¹ãƒˆã—ã€å‹•ä½œã™ã‚‹éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ã„ã‚‹ã“ã¨ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:38
msgid ""
"Tested **Vosk STT** (:ref:`test_vosk`) and chosen the right language pack"
" (e.g., ``en-us``)."
msgstr ""
"**Vosk STT** ï¼ˆ :ref:`test_vosk` ï¼‰ã‚’ãƒ†ã‚¹ãƒˆã—ã€é©åˆ‡ãªè¨€èªãƒ‘ãƒƒã‚¯ï¼ˆä¾‹ï¼š ``en-us`` ï¼‰ã‚’é¸æŠã—ã¦ã„ã‚‹ã“ã¨ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:39
msgid ""
"Installed **Ollama** (:ref:`download_ollama`) on your Pi or another "
"computer, and downloaded a model such as ``llama3.2:3b`` (or a smaller "
"one like ``moondream:1.8b`` if memory is limited)."
msgstr ""
"Pi ã¾ãŸã¯åˆ¥ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã« **Ollama** ï¼ˆ :ref:`download_ollama` ï¼‰ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€"
"``llama3.2:3b`` ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã“ã¨"
"ï¼ˆãƒ¡ãƒ¢ãƒªãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã¯ ``moondream:1.8b`` ã®ã‚ˆã†ãªå°ã•ã„ãƒ¢ãƒ‡ãƒ«ï¼‰ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:44
msgid "Run the Code"
msgstr "ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹"

#: ../ai_interaction/python_local_chatbot.rst:46
msgid "Open the example script:"
msgstr "ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é–‹ãã¾ã™ï¼š"

#: ../ai_interaction/python_local_chatbot.rst:53
msgid "Update the parameters as needed:"
msgstr "å¿…è¦ã«å¿œã˜ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã¾ã™ï¼š"

#: ../ai_interaction/python_local_chatbot.rst:55
msgid ""
"``stt = Vosk(language=\"en-us\")``: Change this to match your "
"accent/language package (e.g., ``en-us``, ``zh-cn``, ``es``)."
msgstr ""
"``stt = Vosk(language=\"en-us\")`` ï¼š"
"ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼è¨€èªãƒ‘ãƒƒã‚¯ã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¾ã™ï¼ˆä¾‹ï¼š ``en-us`` ã€ ``zh-cn`` ã€ ``es`` ï¼‰ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:56
msgid ""
"``tts.set_model(\"en_US-amy-low\")``: Replace with the Piper voice model "
"you verified in :ref:`test_piper`."
msgstr ""
"``tts.set_model(\"en_US-amy-low\")`` ï¼š"
":ref:`test_piper` ã§ç¢ºèªã—ãŸ Piper ã®éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:57
msgid ""
"``llm = Ollama(ip=\"localhost\", model=\"llama3.2:3b\")``: Update both "
"``ip`` and ``model`` to your own setup."
msgstr ""
"``llm = Ollama(ip=\"localhost\", model=\"llama3.2:3b\")`` ï¼š"
"``ip`` ã¨ ``model`` ã®ä¸¡æ–¹ã‚’è‡ªåˆ†ã®ç’°å¢ƒã«åˆã‚ã›ã¦æ›´æ–°ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:59
msgid ""
"``ip``: If Ollama runs on the **same Pi**, use ``localhost``. If Ollama "
"runs on another computer in your LAN, enable **Expose to network** in "
"Ollama and set ``ip`` to that computerâ€™s LAN IP."
msgstr ""
"``ip`` ï¼šOllama ãŒ **åŒã˜ Pi** ã§å‹•ä½œã—ã¦ã„ã‚‹å ´åˆã¯ ``localhost`` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
"Ollama ãŒ LAN å†…ã®åˆ¥ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§å‹•ä½œã—ã¦ã„ã‚‹å ´åˆã¯ã€Ollama ã§ **Expose to network** ã‚’æœ‰åŠ¹ã«ã—ã€"
"``ip`` ã‚’ãã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã® LAN IP ã«è¨­å®šã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:60
msgid ""
"``model``: Must exactly match the model name you downloaded/activated in "
"Ollama."
msgstr ""
"``model`` ï¼šOllama ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼æœ‰åŠ¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«åã¨å®Œå…¨ã«ä¸€è‡´ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:62
msgid "Run the script:"
msgstr "ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ï¼š"

#: ../ai_interaction/python_local_chatbot.rst:69
msgid "After running, you should see:"
msgstr "å®Ÿè¡Œã™ã‚‹ã¨ã€æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š"

#: ../ai_interaction/python_local_chatbot.rst:71
msgid "The bot greets you with a spoken welcome message."
msgstr "ãƒœãƒƒãƒˆãŒéŸ³å£°ã®ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§æŒ¨æ‹¶ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:72
msgid "It waits for speech input."
msgstr "éŸ³å£°å…¥åŠ›ã‚’å¾…ã¡å—ã‘ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:73
msgid "Vosk transcribes your speech into text."
msgstr "Vosk ãŒéŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:74
msgid "The text is sent to Ollama, which streams back a reply."
msgstr "ãƒ†ã‚­ã‚¹ãƒˆãŒ Ollama ã«é€ä¿¡ã•ã‚Œã€è¿”ä¿¡ãŒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¿”ã£ã¦ãã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:75
msgid ""
"The reply is cleaned (removing hidden reasoning) and spoken aloud by "
"Piper."
msgstr ""
"è¿”ä¿¡ã¯ï¼ˆéš ã‚ŒãŸæ¨è«–éƒ¨åˆ†ã‚’é™¤å»ã—ã¦ï¼‰æ•´å½¢ã•ã‚Œã€Piper ã«ã‚ˆã‚ŠéŸ³å£°ã§èª­ã¿ä¸Šã’ã‚‰ã‚Œã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:76
msgid "Stop the program anytime with ``Ctrl+C``."
msgstr "``Ctrl+C`` ã§ã„ã¤ã§ã‚‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’åœæ­¢ã§ãã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:81
msgid "Code"
msgstr "ã‚³ãƒ¼ãƒ‰"

#: ../ai_interaction/python_local_chatbot.rst:172
msgid "Code Analysis"
msgstr "ã‚³ãƒ¼ãƒ‰è§£æ"

#: ../ai_interaction/python_local_chatbot.rst:174
msgid "**Imports and global setup**"
msgstr "**ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š** "

#: ../ai_interaction/python_local_chatbot.rst:184
msgid ""
"Brings in the three subsystems you built earlier: **Vosk** for speech-to-"
"text (STT), **Ollama** for the LLM, and **Piper** for text-to-speech "
"(TTS)."
msgstr ""
"ã“ã‚Œã¾ã§æ§‹ç¯‰ã—ã¦ããŸ 3 ã¤ã®ã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’å–ã‚Šè¾¼ã¿ã¾ã™ï¼š"
"éŸ³å£°â†’ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ STT ï¼‰ã® **Vosk** ã€LLM ã® **Ollama** ã€"
"ãƒ†ã‚­ã‚¹ãƒˆâ†’éŸ³å£°ï¼ˆ TTS ï¼‰ã® **Piper** ã§ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:189
msgid "**Initialize STT (Vosk)**"
msgstr "**STTï¼ˆ Vosk ï¼‰ã‚’åˆæœŸåŒ–** "

#: ../ai_interaction/python_local_chatbot.rst:195
msgid ""
"Loads the Vosk model for US English. Change the language code (e.g., "
"``zh-cn``, ``es``) to match your voice pack for better accuracy."
msgstr ""
"ç±³å›½è‹±èªç”¨ã® Vosk ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚"
"ç²¾åº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã€è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹ï¼š ``zh-cn`` ã€ ``es`` ï¼‰ã‚’éŸ³å£°ãƒ‘ãƒƒã‚¯ã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:200
msgid "**Initialize TTS (Piper)**"
msgstr "**TTSï¼ˆ Piper ï¼‰ã‚’åˆæœŸåŒ–** "

#: ../ai_interaction/python_local_chatbot.rst:207
msgid ""
"Creates a Piper engine and selects a specific voice. Pick a model youâ€™ve "
"tested in :ref:`test_piper`. Lower-quality voices are faster and use less"
" CPU."
msgstr ""
"Piper ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆã—ã€ç‰¹å®šã®éŸ³å£°ã‚’é¸æŠã—ã¾ã™ã€‚"
":ref:`test_piper` ã§ãƒ†ã‚¹ãƒˆæ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚"
"ä½å“è³ªï¼ˆ low ï¼‰ã®éŸ³å£°ã¯é«˜é€Ÿã§ã€CPU ä½¿ç”¨é‡ã‚‚å°‘ãªããªã‚Šã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:212
msgid "**LLM instructions and welcome line**"
msgstr "**LLM ã®æŒ‡ç¤ºæ–‡ã¨ã‚¦ã‚§ãƒ«ã‚«ãƒ è¡¨ç¤º** "

#: ../ai_interaction/python_local_chatbot.rst:222
msgid "Two key UX choices:"
msgstr "UX ä¸Šã®é‡è¦ãª 2 ã¤ã®ãƒã‚¤ãƒ³ãƒˆï¼š"

#: ../ai_interaction/python_local_chatbot.rst:224
msgid "Keep **answers short and direct** (helps with TTS clarity)."
msgstr "**å›ç­”ã¯çŸ­ãç«¯çš„ã«** ä¿ã¤ï¼ˆ TTS ã®èãå–ã‚Šã‚„ã™ã•ã«å½¹ç«‹ã¡ã¾ã™ï¼‰ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:225
msgid "Explicitly forbid hidden â€œchain-of-thoughtâ€ tags to reduce noisy outputs."
msgstr "ãƒã‚¤ã‚ºã®å¤šã„å‡ºåŠ›ã‚’æ¸›ã‚‰ã™ãŸã‚ã€éš ã‚ŒãŸã€Œ chain-of-thought ã€ã‚¿ã‚°ã‚’æ˜ç¤ºçš„ã«ç¦æ­¢ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:229
msgid "**Connect to Ollama and set conversation scope**"
msgstr "**Ollama ã«æ¥ç¶šã—ã¦ä¼šè©±ç¯„å›²ã‚’è¨­å®š** "

#: ../ai_interaction/python_local_chatbot.rst:237
msgid ""
"``ip=\"localhost\"`` assumes the Ollama server runs on the same Pi. If it"
" runs on another LAN machine, put that computerâ€™s **LAN IP** and enable "
"*Expose to network* in Ollama."
msgstr ""
"``ip=\"localhost\"`` ã¯ã€Ollama ã‚µãƒ¼ãƒãƒ¼ãŒåŒã˜ Pi ã§å‹•ä½œã—ã¦ã„ã‚‹å‰æã§ã™ã€‚"
"LAN å†…ã®åˆ¥ãƒã‚·ãƒ³ã§å‹•ä½œã—ã¦ã„ã‚‹å ´åˆã¯ã€ãã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã® **LAN IP** ã‚’æŒ‡å®šã—ã€"
"Ollama ã§ *Expose to network* ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:238
msgid ""
"``set_max_messages(20)`` keeps a short conversational history. Lower this"
" if memory/latency is tight."
msgstr ""
"``set_max_messages(20)`` ã¯ã€ä¼šè©±å±¥æ­´ã‚’çŸ­ãä¿ã¡ã¾ã™ã€‚"
"ãƒ¡ãƒ¢ãƒªï¼ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒå³ã—ã„å ´åˆã¯ã€ã“ã®å€¤ã‚’ä¸‹ã’ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:240
msgid "**Strip hidden reasoning / tags before speaking**"
msgstr "**è©±ã™å‰ã«éš ã—æ¨è«–ï¼ã‚¿ã‚°ã‚’é™¤å»** "

#: ../ai_interaction/python_local_chatbot.rst:253
msgid ""
"Some models may emit internal-style tags (e.g., ``<think>â€¦``). This "
"function removes those so your TTS **only** speaks the final answer."
msgstr ""
"ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã¯å†…éƒ¨ç”¨ã®ã‚¿ã‚°ï¼ˆä¾‹ï¼š ``<think>â€¦`` ï¼‰ã‚’å‡ºåŠ›ã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚"
"ã“ã®é–¢æ•°ã¯ãã‚Œã‚‰ã‚’é™¤å»ã—ã€TTS ãŒæœ€çµ‚å›ç­” **ã®ã¿** ã‚’èª­ã¿ä¸Šã’ã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:256
msgid ""
"**Tip:** If you see other artifacts on screen (because you stream raw "
"tokens), this function already ensures **spoken** output stays clean."
msgstr ""
"**ãƒ’ãƒ³ãƒˆï¼š** ç”Ÿãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã—ã¦ã„ã‚‹ãŸã‚ç”»é¢ä¸Šã«ä»–ã®æ–­ç‰‡ãŒè¦‹ãˆã¦ã‚‚ã€"
"ã“ã®é–¢æ•°ã«ã‚ˆã‚Š **éŸ³å£°** å‡ºåŠ›ã¯ã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã«ä¿ãŸã‚Œã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:258
msgid "**Main loop: greet once, then listen â†’ think â†’ speak**"
msgstr "**ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼šä¸€åº¦æŒ¨æ‹¶ã—ã€ãã®å¾Œã¯ èã â†’ è€ƒãˆã‚‹ â†’ è©±ã™** "

#: ../ai_interaction/python_local_chatbot.rst:265
msgid "Greets the user via terminal and speaker. Happens once at startup."
msgstr "ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã¨ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æŒ¨æ‹¶ã—ã¾ã™ã€‚èµ·å‹•æ™‚ã« 1 å›ã ã‘å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:267
msgid "**Listen (streaming STT with live partials)**"
msgstr "**èãï¼ˆãƒ©ã‚¤ãƒ–éƒ¨åˆ†çµæœä»˜ãã® STT ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰** "

#: ../ai_interaction/python_local_chatbot.rst:281
msgid ""
"``stream=True`` yields **partial** transcripts for immediate feedback and"
" a **final** transcript when the utterance ends."
msgstr ""
"``stream=True`` ã«ã™ã‚‹ã¨ã€å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ã® **éƒ¨åˆ†** æ–‡å­—èµ·ã“ã—ã¨ã€"
"ç™ºè©±çµ‚äº†æ™‚ã® **æœ€çµ‚** æ–‡å­—èµ·ã“ã—ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:282
msgid "The final recognized text is stored in ``text`` and printed once."
msgstr "æœ€çµ‚çš„ã«èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¯ ``text`` ã«ä¿å­˜ã•ã‚Œã€1 å›ã ã‘è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:284
msgid "**Guard:** If nothing was recognized, you skip the LLM call:"
msgstr "**ã‚¬ãƒ¼ãƒ‰ï¼š** ä½•ã‚‚èªè­˜ã•ã‚Œãªã‹ã£ãŸå ´åˆã¯ã€LLM å‘¼ã³å‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ï¼š"

#: ../ai_interaction/python_local_chatbot.rst:293
msgid "This avoids sending empty prompts to the model (saves time and tokens)."
msgstr "ã“ã‚Œã«ã‚ˆã‚Šã€ç©ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ã«é€ä¿¡ã™ã‚‹ã“ã¨ã‚’é¿ã‘ã‚‰ã‚Œã¾ã™ï¼ˆæ™‚é–“ã¨ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¯€ç´„ï¼‰ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:295
msgid "**Think (LLM) with streamed printing**"
msgstr "**è€ƒãˆã‚‹ï¼ˆ LLM ï¼šã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºï¼‰** "

#: ../ai_interaction/python_local_chatbot.rst:307
msgid ""
"Sends the final transcript to the local LLM and **prints tokens as they "
"arrive** for low latency."
msgstr ""
"æœ€çµ‚æ–‡å­—èµ·ã“ã—ã‚’ãƒ­ãƒ¼ã‚«ãƒ« LLM ã«é€ä¿¡ã—ã€ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®ãŸã‚ "
"**åˆ°ç€ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’é€æ¬¡è¡¨ç¤º** ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:308
msgid ""
"Meanwhile, you accumulate the full reply in ``reply_accum`` for post-"
"processing."
msgstr ""
"åŒæ™‚ã«ã€å¾Œå‡¦ç†ã®ãŸã‚ã«å›ç­”å…¨æ–‡ã‚’ ``reply_accum`` ã«è“„ç©ã—ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:310
msgid ""
"**Note:** If youâ€™d rather **not** show raw tokens, set ``stream=False`` "
"and just print the final string."
msgstr ""
"**æ³¨ï¼š** ç”Ÿãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¡¨ç¤ºã—ãŸããªã„å ´åˆã¯ ``stream=False`` ã«è¨­å®šã—ã€æœ€çµ‚æ–‡å­—åˆ—ã ã‘ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:312
msgid "**Speak (clean first, then TTS once)**"
msgstr "**è©±ã™ï¼ˆæ•´å½¢ã—ã¦ã‹ã‚‰ TTS ã‚’ 1 å›ã ã‘å®Ÿè¡Œï¼‰** "

#: ../ai_interaction/python_local_chatbot.rst:322
msgid "Cleans the final text to remove hidden tags, then **speaks exactly once**."
msgstr "æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éš ã—ã‚¿ã‚°ã‚’é™¤å»ã—ã¦æ•´å½¢ã—ã€ãã®å¾Œ **1 å›ã ã‘èª­ã¿ä¸Šã’ã¾ã™** ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:323
msgid "Keeping TTS to a single pass avoids repeated prompts like â€œ[LLM] / [SAY]â€."
msgstr "TTS ã‚’ 1 å›ã®å®Ÿè¡Œã«ã™ã‚‹ã“ã¨ã§ã€ã€Œ[LLM] / [SAY]ã€ã®ã‚ˆã†ãªç¹°ã‚Šè¿”ã—ã®èª­ã¿ä¸Šã’ã‚’é˜²ã’ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:326
msgid "**Exit and teardown**"
msgstr "**çµ‚äº†ã¨å¾Œå§‹æœ«** "

#: ../ai_interaction/python_local_chatbot.rst:336
msgid ""
"Use **Ctrl+C** to stop. The bot says a short goodbye to signal a clean "
"exit."
msgstr ""
"**Ctrl+C** ã§åœæ­¢ã§ãã¾ã™ã€‚"
"ãƒœãƒƒãƒˆã¯çŸ­ã„åˆ¥ã‚Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è©±ã—ã€æ­£å¸¸çµ‚äº†ã—ãŸã“ã¨ã‚’çŸ¥ã‚‰ã›ã¾ã™ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:342
msgid "Troubleshooting & FAQ"
msgstr "ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ FAQ"

#: ../ai_interaction/python_local_chatbot.rst:344
msgid "**Model is too large (memory error)**"
msgstr "**ãƒ¢ãƒ‡ãƒ«ãŒå¤§ãã™ãã‚‹ï¼ˆãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ï¼‰** "

#: ../ai_interaction/python_local_chatbot.rst:346
msgid ""
"Use a smaller model like ``moondream:1.8b`` or run Ollama on a more "
"powerful computer."
msgstr ""
"``moondream:1.8b`` ã®ã‚ˆã†ãªå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€"
"ã‚ˆã‚Šå¼·åŠ›ãªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ Ollama ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:348
msgid "**No response from Ollama**"
msgstr "**Ollama ã‹ã‚‰å¿œç­”ãŒãªã„** "

#: ../ai_interaction/python_local_chatbot.rst:350
msgid ""
"Make sure Ollama is running (``ollama serve`` or desktop app open). If "
"remote, enable **Expose to network** and check IP address."
msgstr ""
"Ollama ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆ ``ollama serve`` ã¾ãŸã¯ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªãŒé–‹ã„ã¦ã„ã‚‹ã“ã¨ï¼‰ã€‚"
"ãƒªãƒ¢ãƒ¼ãƒˆã®å ´åˆã¯ **Expose to network** ã‚’æœ‰åŠ¹ã«ã—ã€IP ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:352
msgid "**Vosk not recognizing speech**"
msgstr "**Vosk ãŒéŸ³å£°ã‚’èªè­˜ã—ãªã„** "

#: ../ai_interaction/python_local_chatbot.rst:354
msgid ""
"Verify your microphone works. Try another language pack (``zh-cn``, "
"``es`` etc.) if needed."
msgstr ""
"ãƒã‚¤ã‚¯ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
"å¿…è¦ã«å¿œã˜ã¦åˆ¥ã®è¨€èªãƒ‘ãƒƒã‚¯ï¼ˆ ``zh-cn`` ã€ ``es`` ãªã©ï¼‰ã‚‚è©¦ã—ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:356
msgid "**Piper silent or errors**"
msgstr "**Piper ãŒç„¡éŸ³ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹** "

#: ../ai_interaction/python_local_chatbot.rst:358
msgid ""
"Confirm the chosen voice model is downloaded and tested in "
":ref:`test_piper`."
msgstr ""
"é¸æŠã—ãŸéŸ³å£°ãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã‚ã‚Šã€"
":ref:`test_piper` ã§ãƒ†ã‚¹ãƒˆæ¸ˆã¿ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

#: ../ai_interaction/python_local_chatbot.rst:360
msgid "**Answers too long or off-topic**"
msgstr "**å›ç­”ãŒé•·ã™ãã‚‹ï¼è©±ãŒãã‚Œã‚‹** "

#: ../ai_interaction/python_local_chatbot.rst:362
msgid "Edit ``INSTRUCTIONS`` to add: **â€œKeep answers short and to the point.â€**"
msgstr "``INSTRUCTIONS`` ã‚’ç·¨é›†ã—ã¦ã€æ¬¡ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼š **ã€ŒKeep answers short and to the point.ã€** "
